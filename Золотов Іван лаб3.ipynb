{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmcWSc1-7eIn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.client import device_lib\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W3Ss6ZH8H4T"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/навчальне/data/netflix_titles.csv\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "MRAQcGNliME5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSg5zrRIcxns"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3tkKdQcJ1ka"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux_x6m6yOnHP"
      },
      "outputs": [],
      "source": [
        "df = df.drop([\"description\", \"duration\", \"listed_in\", \"cast\", \"date_added\", \"title\", \"director\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7ESXDvoitkQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "df['show_id'] = encoder.fit_transform(df['show_id'])\n",
        "df['type'] = encoder.fit_transform(df['type'])\n",
        "df['country'] = encoder.fit_transform(df['country'])\n",
        "df['rating'] = encoder.fit_transform(df['rating'])"
      ],
      "metadata": {
        "id": "KUta4cIAeN0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "l27RYQT4fSrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('country:', df['country'].nunique(), '\\n')\n",
        "print('release_year:', df['release_year'].nunique(), '\\n')\n",
        "print('rating:', df['rating'].nunique(), '\\n')"
      ],
      "metadata": {
        "id": "HLbzeQaDhfB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
      ],
      "metadata": {
        "id": "u8ZigKRsjb60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTPF9_DBLh0O"
      },
      "outputs": [],
      "source": [
        "X = df.drop([\"rating\"], axis=1)\n",
        "y = df[\"rating\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAYI4xcsOHVx"
      },
      "outputs": [],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L90v7g7jOLpg"
      },
      "outputs": [],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toBYveRjREcw"
      },
      "source": [
        "KERAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoHv8cQTORNn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='softmax'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdHguFt6PnT9"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "print(f'accuracy: {accuracy*100}%')"
      ],
      "metadata": {
        "id": "hWeLuj-C6hvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMAGE"
      ],
      "metadata": {
        "id": "1GeEQ5WO8EuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import random\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, LeakyReLU\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as image\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, f1_score , confusion_matrix\n",
        "\n",
        "\n",
        "image_df =  pd.read_csv(\"/content/drive/MyDrive/навчальне/data/lab3/sports.csv\")"
      ],
      "metadata": {
        "id": "IHe1cOAV8KVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df"
      ],
      "metadata": {
        "id": "0bB_JCrtXnNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total number of target classes : {len(image_df.labels.unique())}\")"
      ],
      "metadata": {
        "id": "I1_OZxUsbMjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_to_keep = ['disc golf', 'field hockey', 'golf', 'hurdles', 'polo']\n",
        "\n",
        "image_df = image_df[image_df['labels'].isin(labels_to_keep)]\n",
        "\n",
        "image_df"
      ],
      "metadata": {
        "id": "PXkFZjMMEHhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total number of target classes : {len(image_df.labels.unique())}\")"
      ],
      "metadata": {
        "id": "iULUPeVmEgRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {\n",
        "             \"train_data\" : \"/content/drive/MyDrive/навчальне/data/lab3/train\",\n",
        "             \"valid_data\" : \"/content/drive/MyDrive/навчальне/data/lab3/valid\",\n",
        "             \"test_data\" : \"/content/drive/MyDrive/навчальне/data/lab3/test\"\n",
        "          }\n",
        "\n",
        "all_data = []\n",
        "for path in dataset.values():\n",
        "    data = {\"imgpath\": [] , \"labels\": [] }\n",
        "    category = os.listdir(path)\n",
        "\n",
        "    for folder in category:\n",
        "        folderpath = os.path.join(path , folder)\n",
        "        filelist = os.listdir(folderpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(folderpath, file)\n",
        "            data[\"imgpath\"].append(fpath)\n",
        "            data[\"labels\"].append(folder)\n",
        "\n",
        "\n",
        "    all_data.append(data.copy())\n",
        "    data.clear()\n",
        "\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame(all_data[0] , index=range(len(all_data[0]['imgpath'])))\n",
        "valid_df = pd.DataFrame(all_data[1] , index=range(len(all_data[1]['imgpath'])))\n",
        "test_df = pd.DataFrame(all_data[2] , index=range(len(all_data[2]['imgpath'])))\n",
        "\n",
        "\n",
        "# #Convert labels to numbers\n",
        "lb = LabelEncoder()\n",
        "train_df['encoded_labels'] = lb.fit_transform(train_df['labels'])\n",
        "valid_df['encoded_labels'] = lb.fit_transform(valid_df['labels'])\n",
        "test_df['encoded_labels'] = lb.fit_transform(test_df['labels'])"
      ],
      "metadata": {
        "id": "YS9kTskIFwb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df = valid_df[valid_df['labels'].isin(labels_to_keep)]\n",
        "train_df = train_df[train_df['labels'].isin(labels_to_keep)]\n",
        "test_df = test_df[test_df['labels'].isin(labels_to_keep)]"
      ],
      "metadata": {
        "id": "ZGBPf5teJ3oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "for i, row in valid_df.sample(n=25).reset_index().iterrows():\n",
        "    plt.subplot(5,5,i+1)\n",
        "    image_path = row['imgpath']\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.title(row[\"labels\"])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gskCpbtmBpf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout , BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers,models,Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "generator = ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
        "    # there could be image augmentation here\n",
        ")\n",
        "\n",
        "# Split the data into three categories.\n",
        "train_images = generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='imgpath',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "valid_images = generator.flow_from_dataframe(\n",
        "    dataframe=valid_df,\n",
        "    x_col='imgpath',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_images = generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='imgpath',\n",
        "    y_col='labels',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "4ikz4V3aHzNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False, # we don`t need a pre-trained top layer (output layer)\n",
        "    weights='imagenet',\n",
        "    pooling='max'\n",
        ")\n",
        "\n",
        "# Freezing the layers of a pretrained neural network\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    pretrained_model.layers[i].trainable = False"
      ],
      "metadata": {
        "id": "uji7dL6-NEXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(train_images.classes))\n",
        "\n",
        "\n",
        "# Data Augmentation Step\n",
        "augment = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "  layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  layers.experimental.preprocessing.RandomContrast(0.1),\n",
        "], name='AugmentationLayer')\n",
        "\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape = (224,224,3), name='inputLayer')\n",
        "x = augment(inputs)\n",
        "pretrain_out = pretrained_model(x, training = False)\n",
        "x = layers.Dense(350)(pretrain_out)\n",
        "x = layers.Activation(activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "x = layers.Dense(num_classes)(x)\n",
        "outputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) # mixed_precision need separated Dense and Activation layers\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.0005),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "7CL2gKmPNM9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=valid_images,\n",
        "    validation_steps=len(valid_images),\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor = \"val_loss\",\n",
        "                               patience = 3,\n",
        "                               restore_best_weights = True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min')\n",
        "    ]\n",
        ")\n",
        "model.save_weights('/content/drive/MyDrive/навчальне/data')"
      ],
      "metadata": {
        "id": "t5fKmwy5GEEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "CmsFFMa7G756"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT"
      ],
      "metadata": {
        "id": "GTFJBQboIacs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "zcpIAYmxIgv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_text = pd.read_csv(\"/content/drive/MyDrive/навчальне/data/lab3.2/bible_data_set.csv\")\n",
        "\n",
        "df_text"
      ],
      "metadata": {
        "id": "jtWwr40jNLjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_text = df_text[['book', 'text']]\n",
        "\n",
        "df_text"
      ],
      "metadata": {
        "id": "lhMlk02zPZ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text3 = df_text['text']\n",
        "Y_text3 = df_text['book']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_text3_train, X_text3_test, Y_text3_train, Y_text3_test = train_test_split(X_text3, Y_text3,  test_size=0.20)"
      ],
      "metadata": {
        "id": "p5Im0d4vQZPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_text3_train)\n",
        "X_text3_train_seq = tokenizer.texts_to_sequences(X_text3_train)\n",
        "X_text3_test_seq = tokenizer.texts_to_sequences(X_text3_test)"
      ],
      "metadata": {
        "id": "HUna_jUsRRIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Padding\n",
        "max_sequence_length = 100\n",
        "X_train_pad = pad_sequences(X_text3_train_seq, maxlen=max_sequence_length)\n",
        "X_test_pad = pad_sequences(X_text3_test_seq, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "l2FvYeDSRa8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model3 = keras.Sequential()\n",
        "model3.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
        "model3.add(LSTM(100))\n",
        "model3.add(Dense(3, activation='sigmoid'))\n",
        "model3.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "VFKWf9onSQco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zzBN-8XpSXI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "id": "icwzmfySSYjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YuBWySeFSeP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model3.fit(X_train_pad, Y_text3_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "q6HUYSxWSgoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model3.evaluate(X_test_pad, Y_text3_test)\n",
        "print(f'Loss: {loss:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "3lEKn5ovS3PV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}